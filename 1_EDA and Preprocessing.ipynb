{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\n",
    "    'font.family':'Times New Roman', \n",
    "    'font.size': 14,  # \n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 14,\n",
    "})\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Coal mine A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_A = []\n",
    "id_A = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_A(num):  \n",
    "    data = pd.read_csv(  \n",
    "        f'origin data/22-3 coal mine A hp{num}.csv',   \n",
    "        usecols=[0, 1, 2],   \n",
    "        names=['tunnel1', 'tunnel2', 'time'],  \n",
    "        skiprows=1  \n",
    "    )  \n",
    "    data = data.set_index(\"time\")  \n",
    "    data.index = pd.to_datetime(data.index)  \n",
    "\n",
    "    list_A.append(data)  \n",
    "    id_A.append(num)  \n",
    "\n",
    "def show_data(data, name):  \n",
    "    fig, ax = plt.subplots(figsize=(8, 5))  \n",
    "    colors = ['#FF6B6B', '#4ECDC4']\n",
    "    data.plot(ax=ax, color=colors)  \n",
    "    ax.set_xlabel('Time')  \n",
    "    ax.set_ylabel('Pressure (MPa)')  \n",
    "    ax.set_title(f'Coal Mine {name}# Hydraulic Support Pressure Data')  \n",
    "    ax.legend(loc='upper right')  \n",
    "    plt.savefig(f'{name}.svg', format='svg', bbox_inches='tight')  \n",
    "    plt.show()  \n",
    "    print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_A(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_A[0], 'A 30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_A(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_A[1], 'A 35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_A(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_A[2], 'A 40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_A(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_A[3], 'A 55')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_A(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_A[4], 'A 75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_A(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_A[5], 'A 90')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Coal mine B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_B = []\n",
    "id_B = []\n",
    "def read_data_B(num):\n",
    "    data = pd.read_csv(\n",
    "        f'origin data/22-4 coal mine B hp{num}.csv', \n",
    "        usecols=[0, 1, 2], \n",
    "        names=['time', 'tunnel1', 'tunnel2'],\n",
    "        skiprows=1\n",
    "        )\n",
    "    \n",
    "    data = data.set_index(\"time\")\n",
    "\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    \n",
    "    list_B.append(data)\n",
    "    id_B.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_B(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_B[-1], 'B 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_B(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_B[-1], 'B 5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_B(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_B[-1], 'B 9')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_B(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_B[-1], 'B 15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_B(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_B[-1], 'B 20')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_B(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_B[-1], 'B 25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_B(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_B[-1], 'B 30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data_B(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(list_B[-1], 'B 35')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_average(dataframes_list, resample_freq='5T'):\n",
    "    resampled_list = []\n",
    "    for df in dataframes_list:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df.index):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        resampled_df = df.resample(resample_freq).mean()\n",
    "        resampled_df['average'] = resampled_df.mean(axis=1) \n",
    "        \n",
    "        resampled_df = resampled_df.interpolate(method='time')\n",
    "\n",
    "        resampled_list.append(resampled_df)\n",
    "    \n",
    "    return resampled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resam_list_A = resample_and_average(list_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resam_list_B = resample_and_average(list_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = '90# Coal Mining Hydraulic Support'\n",
    "fig = px.line(resam_list_B[4], y=['tunnel1', 'tunnel2'], title=title)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_white', \n",
    "    title={'text': title, 'x':0.5, 'xanchor': 'center'}, \n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Value\",\n",
    "    legend_title=\"Tunnel\",\n",
    "    font=dict(\n",
    "        family=\"Times New Roman, Times, serif\", \n",
    "        size=12,\n",
    "        color=\"Black\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "    x=1.01,\n",
    "    y=1.01,\n",
    "    bordercolor=\"Black\",\n",
    "    borderwidth=1\n",
    "))\n",
    "\n",
    "fig.update_layout(width=800, height=400)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df_list_A = []\n",
    "for df in resam_list_A:   \n",
    "    df = df[~((df.index.month == 4) & (df.index.day >= 15) & (df.index.day <= 22))]\n",
    "    \n",
    "    processed_df_list_A.append(df)\n",
    "\n",
    "ndarray_list_A = [df['average'].to_numpy() for df in processed_df_list_A]\n",
    "\n",
    "ndarray_list_B = [df['average'].to_numpy() for df in resam_list_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(ndarray_list_B[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform min-max normalization on a numpy array\n",
    "def min_max_normalize(arr):\n",
    "    return (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
    "\n",
    "def split_normal(ndarray_list):\n",
    "    # Lists to store the divided parts\n",
    "    first_part = []\n",
    "    second_part = []\n",
    "    third_part = []\n",
    "    for arr in ndarray_list:\n",
    "        n = len(arr)\n",
    "        first_part.append(arr[:int(n * 0.6)])\n",
    "        second_part.append(arr[int(n * 0.6):int(n * 0.8)])\n",
    "        third_part.append(arr[int(n * 0.8):])\n",
    "\n",
    "    # Applying min-max normalization to each part\n",
    "    train = [min_max_normalize(arr) for arr in first_part]\n",
    "    valid = [min_max_normalize(arr) for arr in second_part]\n",
    "    test = [min_max_normalize(arr) for arr in third_part]\n",
    "\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A, valid_A, test_A = split_normal(ndarray_list_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A[1].shape, valid_A[1].shape, test_A[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_B, valid_B, test_B = split_normal(ndarray_list_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_B[1].shape, valid_B[1].shape, test_B[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsequences(data_list, sub_length=288, ratio=0.5):\n",
    "    all_subsequences = []\n",
    "\n",
    "    for time_series in data_list:\n",
    "        step = int(sub_length * (1 - ratio))\n",
    "        num_subsequences = (len(time_series) - sub_length) // step + 1\n",
    "\n",
    "        for i in range(int(num_subsequences)):\n",
    "            start_index = int(i * step)\n",
    "            end_index = start_index + sub_length\n",
    "            \n",
    "            if end_index > len(time_series):\n",
    "                break\n",
    "            \n",
    "            subsequence = time_series[start_index:end_index]\n",
    "            all_subsequences.append(subsequence)\n",
    "    \n",
    "    return np.array(all_subsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_B_dataset = generate_subsequences(train_B, ratio=0.75)\n",
    "train_B_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A_dataset = generate_subsequences(train_A, ratio=0.75)\n",
    "train_A_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "datasets = {\n",
    "    'dataset/train_A.pkl': train_A,\n",
    "    'dataset/valid_A.pkl': valid_A,\n",
    "    'dataset/test_A.pkl': test_A,\n",
    "    'dataset/train_B.pkl': train_B,\n",
    "    'dataset/valid_B.pkl': valid_B,\n",
    "    'dataset/test_B.pkl': test_B\n",
    "}\n",
    "\n",
    "for filename, data in datasets.items():\n",
    "    save_to_file(data, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
